{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method for col cleaning\n",
    "years = np.linspace(2015, 2020, 6, dtype=int).tolist()\n",
    "table4 = []\n",
    "for y in years:\n",
    "    n = y-2015\n",
    "    table4_path='./Data_%s/CSV_files_%s/Table_4_Offenses_Offense_Type_by_Bias_Motivation_%s.csv'%(y,y,y)\n",
    "    table4.append(pd.read_csv(table4_path, thousands=','))\n",
    "table4[5]\n",
    "\n",
    "base_col = table4[5].columns.tolist()\n",
    "base_row = table4[5]['Bias_motivation'].tolist()\n",
    "print(base_row)\n",
    "\n",
    "i = 2015\n",
    "for t in table4:\n",
    "    for r in t['Bias_motivation']:\n",
    "        if r not in base_row: print ('row: '+r,i)\n",
    "    i += 1\n",
    "\n",
    "j = 2015\n",
    "for t in table4:\n",
    "    for c in t.columns:\n",
    "        if c not in base_col: print ('col: '+c,j)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "def reg(df, cat):\n",
    "    X = df[['Year', cat]]\n",
    "    y = df[['Total_offenses']]\n",
    "    m1 = LinearRegression().fit(X,y)\n",
    "    yhat = m1.predict(X)\n",
    "    print('intercept: '+str(m1.intercept_))\n",
    "    print('coefficient: '+str(m1.coef_))\n",
    "    df[['Total_offenses']] = yhat\n",
    "    ax = sns.scatterplot(data=df, x='Year', y='Total_offenses', hue=cat)\n",
    "    sns.move_legend(ax, 'upper left', bbox_to_anchor=(1,1))\n",
    "    plt.show()\n",
    "\n",
    "def reg_plot(cats):\n",
    "    cat_list = cats.to_list()\n",
    "    cat_list = list(dict.fromkeys(cat_list))\n",
    "    for cat in cat_list:\n",
    "        cat_name = 'is_' + str(cat)\n",
    "        reg(table_1, cat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie charts\n",
    "def plot_pie(df):\n",
    "    df = df.drop(['Bias_motivation', 'Total_offenses', 'Year', 'Category'],axis=1)\n",
    "\n",
    "    data = df.iloc[2,:].to_numpy().tolist()\n",
    "    labels = df.columns.to_list()\n",
    "    colors = sns.color_palette('pastel')[0:15]\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plt.pie(data, labels = labels, colors = colors, autopct='%.1f%%')\n",
    "    l = ax.pie(data, autopct='%.1f%%', startangle=-90)\n",
    "\n",
    "    for label, t in zip(labels, l[1]):\n",
    "        x, y = t.get_position()\n",
    "        angle = int(math.degrees(math.atan2(y, x)))\n",
    "        ha = \"left\"\n",
    "\n",
    "        if x<0:\n",
    "            angle -= 180\n",
    "            ha = \"right\"\n",
    "\n",
    "        plt.annotate(label, xy=(x,y), rotation=angle, ha=ha, va=\"center\", rotation_mode=\"anchor\", size=8)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "table_all.groupby('Year').apply(plot_pie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong initial appraoch\n",
    "%sql offense_type << SELECT * FROM table1_19 FULL OUTER JOIN table4_19 ON table1_19.Offenses = table4_19.Total_Offenses\n",
    "\n",
    "offense_type = offense_type.loc[:,~offense_type.columns.duplicated()]\n",
    "offense_type = offense_type.drop(['Total_offenses'],axis=1)\n",
    "offense_type.head()\n",
    "\n",
    "t4_19 = table4_19.drop(['Bias_motivation', 'Total_offenses'],axis=1)\n",
    "sns.barplot(data=t4_19.iloc[1:2], orient = 'h')\n",
    "plt.show()\n",
    "\n",
    "# Simplify Table 4\n",
    "%sql table4_16_type << SELECT Bias_motivation, Total_offenses AS '2016' FROM table4_16 WHERE Bias_motivation IN('Race/Ethnicity/Ancestry:', 'Religion:', 'Sexual Orientation:', 'Disability:', 'Gender:', 'Gender Identity:', 'Multiple-Bias Incidents')\n",
    "%sql table4_17_type << SELECT Bias_motivation, Total_offenses AS '2017' FROM table4_17 WHERE Bias_motivation IN('Race/Ethnicity/Ancestry:', 'Religion:', 'Sexual Orientation:', 'Disability:', 'Gender:', 'Gender Identity:', 'Multiple-Bias Incidents')\n",
    "%sql table4_18_type << SELECT Bias_motivation, Total_offenses AS '2018' FROM table4_18 WHERE Bias_motivation IN('Race/Ethnicity/Ancestry:', 'Religion:', 'Sexual Orientation:', 'Disability:', 'Gender:', 'Gender Identity:', 'Multiple-Bias Incidents')\n",
    "%sql table4_19_type << SELECT Bias_motivation, Total_offenses AS '2019' FROM table4_19 WHERE Bias_motivation IN('Race/Ethnicity/Ancestry:', 'Religion:', 'Sexual Orientation:', 'Disability:', 'Gender:', 'Gender Identity:', 'Multiple-Bias Incidents')\n",
    "\n",
    "# Combine Table 4 from 2016-2019\n",
    "combined_table4 = pd.concat([table4_16_type, table4_17_type, table4_18_type, table4_19_type], axis=1)\n",
    "combined_table4 = combined_table4.loc[:,~combined_table4.columns.duplicated()].copy()\n",
    "combined_table4\n",
    "\n",
    "tidy_table4['Year'] = tidy_table4['Year'].astype(int)\n",
    "sns.lmplot(x='Year', y='Total_offenses', data=tidy_table4, hue='Bias_motivation')\n",
    "plt.show()\n",
    "\n",
    "def plot_by_bm(df):\n",
    "    df['Year'] = df['Year'].astype(float)\n",
    "    sns.lmplot(x='Year', y='Total_offenses', data=df, hue='Bias_motivation')\n",
    "    plt.show()\n",
    "\n",
    "tidy_table4.groupby(['Bias_motivation']).apply(plot_by_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot output~one input groupy by State\n",
    "def plot_single(df, input):\n",
    "    sns.lmplot(x=input, y='Incidents',  col='State', data=df, hue='State')\n",
    "    plt.show()\n",
    "\n",
    "# Plot each input\n",
    "for i in input:\n",
    "    plot_single(table, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reg model variables, coefficient, and intercept\n",
    "def run_regression(input, train, test, output):\n",
    "    X_train = train[input]\n",
    "    X_test = test[input]\n",
    "    y_train = train[output]\n",
    "    y_test = test[output]\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    pred_train = reg.predict(X_train)\n",
    "    pred_test = reg.predict(X_test)\n",
    "\n",
    "    print('variables: '+str(input))\n",
    "    print('coefficient: '+str(reg.coef_))\n",
    "    print('intercept: '+str(reg.intercept_))\n",
    "\n",
    "    train_mse = (np.square(pred_train - y_train)).mean()\n",
    "    test_mse = (np.square(pred_test - y_test)).mean()\n",
    "    print('train_rmse: '+ str(math.sqrt(train_mse)))\n",
    "    print('test_rmse: '+ str(math.sqrt(test_mse)))\n",
    "\n",
    "    train_mae = (np.abs(pred_train - y_train)).mean()\n",
    "    test_mae = (np.abs(pred_test - y_test)).mean()\n",
    "    print('train_mae: '+ str(train_mae))\n",
    "    print('test_mae: '+ str(test_mae))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [UNFINISHED] visualization\n",
    "states = geopandas.read_file('geopandas-tutorial/data/usa-states-census-2014.shp')\n",
    "states.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold to verify variable selection\n",
    "def kfold(input):\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    X = train[input]\n",
    "    reg = LinearRegression()\n",
    "    scores = cross_val_score(reg, X, inc, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1)\n",
    "    acc = cross_val_score(reg, X, inc, cv=kf)\n",
    "    m = sqrt(mean(absolute(scores)))\n",
    "    print('KFold'+str(input)+'RMSE: '+str(m))\n",
    "    # print('accuracy: '+str(acc.mean())+' std: '+str(acc.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['Alabama'\n",
    ",'Alaska'\n",
    ",'Arizona'\n",
    ",'Arkansas'\n",
    ",'California'\n",
    ",'Colorado'\n",
    ",'Connecticut'\n",
    ",'Delaware'\n",
    ",'Florida'\n",
    ",'Georgia'\n",
    ",'Hawaii'\n",
    ",'Idaho'\n",
    ",'Illinois'\n",
    ",'Indiana'\n",
    ",'Iowa'\n",
    ",'Kansas'\n",
    ",'Kentucky'\n",
    ",'Louisiana'\n",
    ",'Maine'\n",
    ",'Maryland'\n",
    ",'Massachusetts'\n",
    ",'Michigan'\n",
    ",'Minnesota'\n",
    ",'Mississippi'\n",
    ",'Missouri'\n",
    ",'Montana'\n",
    ",'Nebraska'\n",
    ",'Nevada'\n",
    ",'New Hampshire'\n",
    ",'New Jersey'\n",
    ",'New Mexico'\n",
    ",'New York'\n",
    ",'North Carolina'\n",
    ",'North Dakota'\n",
    ",'Ohio'\n",
    ",'Oklahoma'\n",
    ",'Oregon'\n",
    ",'Pennsylvania'\n",
    ",'Rhode Island'\n",
    ",'South Carolina'\n",
    ",'South Dakota'\n",
    ",'Tennessee'\n",
    ",'Texas'\n",
    ",'Utah'\n",
    ",'Vermont'\n",
    ",'Virginia'\n",
    ",'Washington'\n",
    ",'West Virginia'\n",
    ",'Wisconsin'\n",
    ",'Wyoming']\n",
    "\n",
    "for l in list:\n",
    "    d = df.loc[df['State'] == l]\n",
    "    print(l+str(d.shape[0]))\n",
    "\n",
    "df.loc[df['State'] == 'Mississippi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['Temperature', 'Log_GDP', 'Marriage_Rate', 'Education_Rate']\n",
    "inc = train['Incidents']\n",
    "\n",
    "# Anova F test for single variable selection\n",
    "def anova(var):\n",
    "    f = 'Incidents ~ ' + var\n",
    "    d = smf.ols(formula=f, data=train)\n",
    "    model = d.fit()\n",
    "    a = sm.stats.anova_lm(model)\n",
    "    print(a)\n",
    "    \n",
    "for v in var: anova(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**\n",
    "We first ran ANOVA F-tests on each of the four single-predictor models (X=’Log_GDP’ / ‘Temperature’ / ‘Marriage Rate’ / ‘Education Rate’, y=’Incidents’), since F-stats shows their improvement in significance compared to the intercept-only (null) model. The results show that ’Log_GDP’, ‘Temperature’, and ‘Marriage Rate’ have a p-value less than 0.05, which is significant; among these predictors, log GDP has the smallest p-value, which is 7.04-68. Therefore, we choose log GDP as the input of our one-variable model.\n",
    "\n",
    "**Evaluation of significance**\n",
    "For our model with log GDP as predictor, we ran t-test in OLS regression for verification. We got p-values less than 0.05 for both training and testing sets, which are significant results. Therefore, we confirm that our choice of **log GDP is significant** to predict hate crime incidents, and **log GDP is our best single predictor**.\n",
    "\n",
    "**1.2 Determine the combination of more than one predictors that best predicts the hate crime incidents.** \n",
    "\n",
    "**Methods** We conducted step-wise model selection by using Log Likelihood Ratio test, and then use OLS regression to check the model.\n",
    "\n",
    "- On top of the best one-predictor model, we ran log likelihood ratio tests to determine if we can improve it by adding one more predictor. We iterated this process from raising one predictor to two, two predictors to three, and finally three predictors to four, until we found the optimal combination of predictors for the model. \n",
    " \n",
    "- In our case, the log likelihood ratio tests if the performance of our previously selected model changes significantly after adding one parameter. Specifically, we compare the best model so far (with variables selected from previous tests) and a new model in which we added a new variable. If the p-value of log likelihood ratio is less than 0.5, which is a significant difference, we argue that adding this variable has the potential to improve the model’s goodness of fit. After selecting a new model, we iterated this process by introducing another predictor, and deciding whether to include it until we found the best combination of inputs.\n",
    "\n",
    "- After running the Log Likelihood Ratio test, we ran OLS regression on the model with the selected predictors to verify that each input in our newly-selected model has a significant effect on the output (p < 0.05). If all input has p-values less than .05, we confirm that the newly-selected model is the best model so far.\n",
    "the additional one variable we selected has the most significance in improving model performance.\n",
    "\n",
    "**Analysis** We tested three possible two-predictors models by using the log likelihood ratio test. The results show that adding a second predictor to our best one-predictor model (X = log GDP) does improve the model’s goodness of fit. The p-values for all three possible two-predictors models are less than 0.05. However, the model with **log GDP and temperature** is the two-predictors model with the lowest p-value, which is 5.94e-10. Thus we selected his two-predictors model as our new best model. \n",
    "\n",
    "**Evaluation of significance** We also ran the OLS regression that fits a regression model on log GDP and temperature for both testing and training data. The results show that the p-values are less than 0.05,  which means the predictors in the current two-predictors model are statistically significant. This confirms that the model with inputs **(X = log GDP + Temperature)** is better than the previous model and we should include both inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "- Summary:\n",
    "  - When GDP increases 1 million dollars, hate crime increases 66 incidents.\n",
    "  - When Year Average Temperature increases 1 Fahrenheit, hate crime decreases 8 incidents.\n",
    "  - When Education Rate increases 1 %, hate crime decreases 7 incidents.\n",
    "  - When Marriage increases 1 unit, hate crime decreases 4 incidents.\n",
    "  \n",
    "- Prediction: \n",
    "  - Vermont at 2020 when \n",
    "  - GDP = 29064.6 million dollars, \n",
    "  - Year Average Temperature = 44.8 Fahrenheit, \n",
    "  - Marriage Rate = 6.0%, \n",
    "  - Education Rate = 42.0%, \n",
    "  - hate crime incidents is predicted to be 51.16, while the actual incidents number is 60.\n",
    "- Oddities: \n",
    "  - Hate crime incidents should be integers in real world, but our predictions are floats.\n",
    "  - Hate crime incidents should be all positive in real world, but we sometimes get negative prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = sm.OLS(inc, train[['Temperature', 'Log_GDP']]).fit()\n",
    "llr(tg, ['Temperature', 'Log_GDP', 'Marriage_Rate'])\n",
    "llr(tg, ['Temperature', 'Log_GDP', 'Education_Rate'])\n",
    "llr(tg, ['Temperature', 'Log_GDP', 'Marriage_Rate', 'Education_Rate'])\n",
    "\n",
    "summary(train, ['Temperature', 'Log_GDP'])\n",
    "summary(train, ['Temperature', 'Log_GDP', 'Marriage_Rate'])\n",
    "summary(train, ['Temperature', 'Log_GDP', 'Education_Rate'])\n",
    "summary(train, ['Temperature', 'Log_GDP', 'Marriage_Rate', 'Education_Rate'])\n",
    "\n",
    "repeat(['Temperature', 'Log_GDP'], 200)\n",
    "repeat(['Temperature', 'Log_GDP', 'Is_Covid'], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation between each input (predictor) and the output (incidents)\n",
    "var = train.columns[3:8]\n",
    "for v in var:\n",
    "    sns.lmplot(data=train, x=v, y='Incidents')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linearity check** There's a linear relationship between predictors and response variables.\n",
    "  \n",
    "We used scatter plots to check the linear relationship between the predictors and response variables. After we created the scatter plots, we recognized that the plots for population and GDP are non-linear. This means that these two predictors failed to meet the linearity assumption. Therefore, we decided to transform these predictors by taking the logarithm of these predictors before we fit them into our multilinear regression model. In future analysis, the population and GDP we referred to are actually log population and log GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varl = []\n",
    "import itertools\n",
    "for l in range(len(var) + 1):\n",
    "    for sub in itertools.combinations(var, l):\n",
    "        varl.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F test for significance evaluation\n",
    "def anova(f1, f2):\n",
    "    d1 = smf.ols(formula=f1, data=train)\n",
    "    model1 = d1.fit()\n",
    "    d2 = smf.ols(formula=f2, data=train)\n",
    "    model2 = d2.fit()\n",
    "    a = sm.stats.anova_lm(model1, model2)\n",
    "    print(a)\n",
    "\n",
    "# Moreover, F test (p-value) for evaluation of significance \n",
    "anova('Incidents ~ Temperature + Log_GDP + Education_Rate', 'Incidents ~ Temperature + Log_GDP + Education_Rate + Marriage_Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check: rmse doesn't change significantly after adding Is_Covid\n",
    "# The performance is even worse because rmse is larger when Is_Covid is included in the predictors.\n",
    "repeat(['Temperature', 'Log_GDP', 'Education_Rate'], 100)\n",
    "repeat(['Temperature', 'Log_GDP', 'Education_Rate', 'Is_Covid'], 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('info2950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4f2d85c5392bfe8750c4ab00d7c158fb7744f757c95c00317c79e4448bc170e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
